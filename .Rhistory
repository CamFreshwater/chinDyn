# percentage of the mean is included in 95% CI
estCI <- function(n., logMu, logVar) {
mean. <- logMu + (logVar / 2)
int. <- 2.093 * (sqrt((logVar / n.) + ((logVar^2) / (2 * n. - 1))))
low <- exp(mean. - int.) / exp(mean.)
high <- exp(mean. + int.) / exp(mean.)
list(low, high)
}
estCI(20, logMu = logD, logVar = logDVar)
list(mean. low, high)
# Function to iterate across different sample sizes and determine what
# percentage of the mean is included in 95% CI
estCI <- function(n., logMu, logVar) {
mean. <- logMu + (logVar / 2)
int. <- 2.093 * (sqrt((logVar / n.) + ((logVar^2) / (2 * n. - 1))))
low <- mean. - int.
high <- mean. + int.
list(mean. low, high)
# Function to iterate across different sample sizes and determine what
# percentage of the mean is included in 95% CI
estCI <- function(n., logMu, logVar) {
mean. <- logMu + (logVar / 2)
int. <- 2.093 * (sqrt((logVar / n.) + ((logVar^2) / (2 * n. - 1))))
low <- mean. - int.
high <- mean. + int.
list(mean., low, high)
}
estCI(20, logMu = logD, logVar = logDVar)
exp(estCI(20, logMu = logD, logVar = logDVar))
out <- estCI(20, logMu = logD, logVar = logDVar)
sapply(out, function(x) exp(x))
27.26/33.25
27.26/40.56
# Function to iterate across different sample sizes and determine what
# percentage of the mean is included in 95% CI
estCI <- function(n., logMu, logVar) {
mean. <- logMu + (logVar / 2)
int. <- 2.093 * (sqrt((logVar / n.) + ((logVar^2) / (2 * n. - 1))))
low <- -exp(mean. - int.) / exp(mean.)
high <- exp(mean. + int.) / exp(mean.)
list(-low, high)
}
estCI(20, logMu = logD, logVar = logDVar)
estCI(50, logMu = logD, logVar = logDVar)
estCI(100, logMu = logD, logVar = logDVar)
# Function to iterate across different sample sizes and determine what
# percentage of the mean is included in 95% CI
estCI <- function(n., logMu, logVar) {
mean. <- logMu + (logVar / 2)
int. <- 2.093 * (sqrt((logVar / n.) + ((logVar^2) / (2 * n. - 1))))
low <- 1 - exp(mean. - int.) / exp(mean.)
high <- exp(mean. + int.) / exp(mean.) - 1
list(-low, high)
}
estCI(100, logMu = logD, logVar = logDVar)
nSeq <- c(20, 50, 100, 150)
sapply(nSeq, function(x) estCI(x))
sapply(nSeq, function(x) estCI(x, logMu = logD, logVar = logDVar))
nSeq <- c(20, 50, 100, 150, 200)
out <- estCI(100, logMu = logD, logVar = logDVar)
sapply(nSeq, function(x) estCI(x, logMu = logD, logVar = logDVar))
require(MARSS)
require(MARSS); require(tidyverse); require(ggplot2)
# -----
require(tidyverse); require(here)
byDat <- read.csv(read.csv(here("data/salmonData/cwtInd_age2SR_BY.csv"),
stringsAsFactors = FALSE))
here()
byDat <- read.csv(here("data/salmonData/cwtInd_age2SR_BY.csv"),
stringsAsFactors = FALSE)
eyDat <- read.csv(here("data/salmonData/cwtInd_age2SR_OEY.csv"),
stringsAsFactors = FALSE)
head(byDat)
dum <- byDat %>%
gather(key = "stock", value = "surv", -BY)
head(dum)
stockInfo <- read.csv(here("data/salmonData/pstID.csv"),
stringsAsFactors = FALSE)
stockInfo <- read.csv(here("data/salmonData/pstID.csv"),
stringsAsFactors = FALSE)
head(stockInfo)
stockInfo <- read.csv(here("data/salmonData/pstID.csv"),
stringsAsFactors = FALSE)
head(stockInfo)
stockInfo <- read.csv(here("data/salmonData/pstID.csv"),
stringsAsFactors = FALSE)
head(stockInfo)
stockInfo <- read.csv(here("data/salmonData/pstID.csv"),
stringsAsFactors = FALSE)
head(stockInfo)
stockInfo <- read.csv(here("data/salmonData/pstID.csv"),
stringsAsFactors = FALSE) %>%
select(-smoltAgeCode, -adultRunTimingCode, -country -comments)
stockInfo <- read.csv(here("data/salmonData/pstID.csv"),
stringsAsFactors = FALSE) %>%
select(-smoltAgeCode, -adultRunTimingCode, -country, -comments)
head(stockInfor)
head(stockInfo)
?left_join
#Function to clean each dataframe
dum <- byDat %>%
gather(key = "stock", value = "surv", -BY) %>%
left_join(stockInfo)
head(dum)
#Merge and lengthen each dataset
dum <- byDat %>%
gather(key = "stock", value = "surv", -BY) %>%
right_join(stockInfo)
head(dum)
stockInfo <- read.csv(here("data/salmonData/pstID.csv"),
stringsAsFactors = FALSE) %>%
#remove some extra columns to keep things clean
select(-jurisdiction, -oceanStartAge, -terminalNetAge, -maxAge, -smoltAgeCode,
-adultRunTimingCode, -country, -comments)
head(eyDat)
eyDat <- read.csv(here("data/salmonData/cwtInd_age2SR_OEY.csv"),
stringsAsFactors = FALSE)
head(eyDat)
byDat <- read.csv(here("data/salmonData/cwtInd_age2SR_BY.csv"),
stringsAsFactors = FALSE)
eyDat <- read.csv(here("data/salmonData/cwtInd_age2SR_OEY.csv"),
stringsAsFactors = FALSE)
stockInfo <- read.csv(here("data/salmonData/pstID.csv"),
stringsAsFactors = FALSE) %>%
#remove some extra columns to keep things clean
select(-jurisdiction, -oceanStartAge, -terminalNetAge, -maxAge, -smoltAgeCode,
-adultRunTimingCode, -country, -comments)
#Merge and lengthen each dataset
byDat <- byDat %>%
gather(key = "stock", value = "surv", -BY) %>%
left_join(stockInfo)
eyDat <- eyDat %>%
gather(key = "stock", value = "surv", -OEY) %>%
left_join(stockInfo)
str(byDat)
unique(byDat$region)
byDat %>% filter(is.na(region))
dum <- byDat %>%
left_join(stockInfo) %>%
group_by(stock) %>%
filter(!(length(is.na(surv)) < 11))
byDat <- read.csv(here("data/salmonData/cwtInd_age2SR_BY.csv"),
stringsAsFactors = FALSE)
eyDat <- read.csv(here("data/salmonData/cwtInd_age2SR_OEY.csv"),
stringsAsFactors = FALSE)
stockInfo <- read.csv(here("data/salmonData/pstID.csv"),
stringsAsFactors = FALSE) %>%
#remove some extra columns to keep things clean
select(-jurisdiction, -oceanStartAge, -terminalNetAge, -maxAge, -smoltAgeCode,
-adultRunTimingCode, -country, -comments)
dum <- byDat %>%
left_join(stockInfo) %>%
group_by(stock) %>%
filter(!(length(is.na(surv)) < 11))
head(byDat)
#Length each dataset
byDat <- byDat %>%
gather(key = "stock", value = "surv", -BY)
eyDat <- eyDat %>%
gather(key = "stock", value = "surv", -OEY)
dum <- byDat %>%
left_join(stockInfo) %>%
group_by(stock) %>%
filter(!(length(is.na(surv)) < 11))
head(dum)
dum %>%
group_by(stock) %>%
summarize(length(unique(BY)))
dum %>%
group_by(stock) %>%
summarize(length(!is.na(surv)))
dum2 <- dum %>%
group_by(stock) %>%
summarize(length(!is.na(surv)))
tail(dum2)
tail(dum)
dum2$[,2]
dum2[,2]
dum %>%
group_by(stock) %>%
summarize(length(surv))
dum
dum %>% filter(stock == "KLM")
dum %>% filter(stock == "KLM", n = 100)
dum %>%
group_by(stock) %>%
summarize(length(surv)) %>%
print(n=100)
dum %>% filter(stock == "KLM", n = 100) %>% print(n = 100)
dum %>% filter(stock == "KLM") %>% print(n = 100)
dum %>% filter(stock == "NSF") %>% print(n = 100)
# Function to merge and filter each dataset w/ less than 10 years of survival
# data
cleanPST <- function(dat, stockInfo) {
dat %>%
left_join(stockInfo) %>%
group_by(stock) %>%
filter(!(length(is.na(surv)) < 11))
}
byDatWide <- read.csv(here("data/salmonData/cwtInd_age2SR_BY.csv"),
stringsAsFactors = FALSE)
eyDatWide <- read.csv(here("data/salmonData/cwtInd_age2SR_OEY.csv"),
stringsAsFactors = FALSE)
stockInfo <- read.csv(here("data/salmonData/pstID.csv"),
stringsAsFactors = FALSE) %>%
#remove some extra columns to keep things clean
select(-jurisdiction, -oceanStartAge, -terminalNetAge, -maxAge, -smoltAgeCode,
-adultRunTimingCode, -country, -comments)
#Length each dataset
byDat <- byDatWide %>%
gather(key = "stock", value = "surv", -BY)
eyDat <- eyDatWide %>%
gather(key = "stock", value = "surv", -OEY)
# Function to merge and filter each dataset w/ less than 10 years of survival
# data
cleanPST <- function(dat, stockInfo) {
dat %>%
left_join(stockInfo) %>%
group_by(stock) %>%
filter(!(length(is.na(surv)) < 11))
}
byDat <- cleanPST(byDat, stockInfo)
eyDat <- cleanPST(eyDat, stockInfo)
dim(byDat)
#Length each dataset
byDat <- byDatWide %>%
gather(key = "stock", value = "surv", -BY)
dim(byDat)
byDat %>%
group_by(stock) %>%
summarize(length(!is.na(surv)))
byDat %>%
filter(!is.na(surv)) %>%
group_by(stock) %>%
summarize(length(surv))
byDat %>%
filter(!is.na(surv)) %>%
group_by(stock) %>%
summarize(tsLength = length(surv)) %>%
filter(tsLength <= 10) %>%
select(stock) %>%
as.vector()
byDat %>%
filter(!is.na(surv)) %>%
group_by(stock) %>%
summarize(tsLength = length(surv)) %>%
filter(!tsLength <= 10) %>%
select(stock) %>%
as.vector()
longStks$stock
#ID stocks w/ long TS
longStks <- byDat %>%
filter(!is.na(surv)) %>%
group_by(stock) %>%
summarize(tsLength = length(surv)) %>%
filter(!tsLength <= 10)
longStks$stock
# Function to merge and filter each dataset w/ less than 10 years of survival
# data
cleanPST <- function(dat, stockInfo) {
#ID stocks w/ long TS
longStks <- dat %>%
filter(!is.na(surv)) %>%
group_by(stock) %>%
summarize(tsLength = length(surv)) %>%
filter(!tsLength <= 10)
#join and subset
dat %>%
left_join(stockInfo) %>%
filter(stock %in% longStks$stock)
}
byDat <- cleanPST(byDat, stockInfo)
eyDat <- cleanPST(eyDat, stockInfo)
byDat <- byDatWide %>%
gather(key = "stock", value = "surv", -BY)
eyDat <- eyDatWide %>%
gather(key = "stock", value = "surv", -OEY)
# Function to merge and filter each dataset w/ less than 10 years of survival
# data
cleanPST <- function(dat, stockInfo) {
#ID stocks w/ long TS
longStks <- dat %>%
filter(!is.na(surv)) %>%
group_by(stock) %>%
summarize(tsLength = length(surv)) %>%
filter(!tsLength <= 10)
#join and subset
dat %>%
left_join(stockInfo) %>%
filter(stock %in% longStks$stock)
}
byDat <- cleanPST(byDat, stockInfo)
eyDat <- cleanPST(eyDat, stockInfo)
dim(eyDat)
dim(byDat)
write.csv(byDat, here("data", "salmonData", "CLEANcwtInd_age2SR_BY.csv"))
write.csv(eyDat, here("data", "salmonData", "CLEANcwtInd_age2SR_OEY.csv"))
require(here); require(MARSS); require(tidyverse); require(ggplot2)
byDat <- read.csv(here("data/salmonData/CLEANcwtInd_age2SR_BY.csv"),
stringsAsFactors = FALSE)
eyDat <- read.csv(here("data/salmonData/CLEANcwtInd_age2SR_OEY.csv"),
stringsAsFactors = FALSE)
head(byDat)
?write.csv
write.csv(byDat, here("data", "salmonData", "CLEANcwtInd_age2SR_BY.csv"),
row.names = FALSE)
byDat <- byDatWide %>%
gather(key = "stock", value = "surv", -BY)
eyDat <- eyDatWide %>%
gather(key = "stock", value = "surv", -OEY)
# Function to merge and filter each dataset w/ less than 10 years of survival
# data
cleanPST <- function(dat, stockInfo) {
#ID stocks w/ long TS
longStks <- dat %>%
filter(!is.na(surv)) %>%
group_by(stock) %>%
summarize(tsLength = length(surv)) %>%
filter(!tsLength <= 10)
#join and subset
dat %>%
left_join(stockInfo) %>%
filter(stock %in% longStks$stock)
}
byDat <- cleanPST(byDat, stockInfo)
write.csv(byDat, here("data", "salmonData", "CLEANcwtInd_age2SR_BY.csv"),
row.names = FALSE)
eyDat <- cleanPST(eyDat, stockInfo)
write.csv(eyDat, here("data", "salmonData", "CLEANcwtInd_age2SR_OEY.csv"),
row.names = FALSE)
byDat <- read.csv(here("data/salmonData/CLEANcwtInd_age2SR_BY.csv"),
stringsAsFactors = FALSE)
eyDat <- read.csv(here("data/salmonData/CLEANcwtInd_age2SR_OEY.csv"),
stringsAsFactors = FALSE)
?spread
head(byDat)
# Convert to matrices (necessary for DFA)
byDat %>%
spread(key = stock, value = surv)
# Convert to matrices (necessary for DFA)
byMat <- byDat %>%
select(BY, stock, surv) %>%
spread(key = stock, value = surv)
head(byMat)
broodYrs <- unique(byDat$BY)
broodYrs
# Convert to matrices (necessary for DFA)
byMat <- byDat %>%
select(BY, stock, surv) %>%
spread(key = stock, value = surv) %>%
select(-BY) %>%
as.matrix() %>%
t()
str(byMat)
broodYrs <- unique(byDat$BY)
colnames(byMat) <- broodYrs
require(here); require(MARSS); require(tidyverse); require(ggplot2)
byDat <- read.csv(here("data/salmonData/CLEANcwtInd_age2SR_BY.csv"),
stringsAsFactors = FALSE)
eyDat <- read.csv(here("data/salmonData/CLEANcwtInd_age2SR_OEY.csv"),
stringsAsFactors = FALSE)
head(byDat)
unique(byDat$region)
#How many stocks per region?
byDat %>%
group_by(region) %>%
summarize(nStocks = length(unique(stock)))
require(tidyverse); require(here)
byDatWide <- read.csv(here("data/rawData/salmonData/cwtInd_age2SR_BY.csv"),
stringsAsFactors = FALSE)
eyDatWide <- read.csv(here("data/rawData/salmonData/cwtInd_age2SR_OEY.csv"),
stringsAsFactors = FALSE)
stockInfo <- read.csv(here("data/rawData/salmonData/pstID.csv"),
stringsAsFactors = FALSE) %>%
#remove some extra columns to keep things clean
select(-oceanStartAge, -terminalNetAge, -maxAge, -smoltAgeCode,
-adultRunTimingCode, -country, -comments)
#Lengthen each dataset
byDat <- byDatWide %>%
gather(key = "stock", value = "surv", -BY)
eyDat <- eyDatWide %>%
gather(key = "stock", value = "surv", -OEY)
# Function to merge and filter each dataset w/ less than 10 years of survival
# data
cleanPST <- function(dat, stockInfo) {
#ID stocks w/ long TS
longStks <- dat %>%
filter(!is.na(surv)) %>%
group_by(stock) %>%
summarize(tsLength = length(surv)) %>%
filter(!tsLength <= 10)
#join and subset
dat %>%
left_join(stockInfo) %>%
filter(stock %in% longStks$stock)
}
byDat <- cleanPST(byDat, stockInfo)
write.csv(byDat, here("data", "salmonData", "CLEANcwtInd_age2SR_BY.csv"),
row.names = FALSE)
eyDat <- cleanPST(eyDat, stockInfo)
write.csv(eyDat, here("data", "salmonData", "CLEANcwtInd_age2SR_OEY.csv"),
row.names = FALSE)
byDatWide <- read.csv(here("data/salmonData/rawData/cwtInd_age2SR_BY.csv"),
stringsAsFactors = FALSE)
eyDatWide <- read.csv(here("data/salmonData/rawData/cwtInd_age2SR_OEY.csv"),
stringsAsFactors = FALSE)
stockInfo <- read.csv(here("data/salmonData/rawData/pstID.csv"),
stringsAsFactors = FALSE) %>%
#remove some extra columns to keep things clean
select(-oceanStartAge, -terminalNetAge, -maxAge, -smoltAgeCode,
-adultRunTimingCode, -country, -comments)
#Lengthen each dataset
byDat <- byDatWide %>%
gather(key = "stock", value = "surv", -BY)
eyDat <- eyDatWide %>%
gather(key = "stock", value = "surv", -OEY)
# Function to merge and filter each dataset w/ less than 10 years of survival
# data
cleanPST <- function(dat, stockInfo) {
#ID stocks w/ long TS
longStks <- dat %>%
filter(!is.na(surv)) %>%
group_by(stock) %>%
summarize(tsLength = length(surv)) %>%
filter(!tsLength <= 10)
#join and subset
dat %>%
left_join(stockInfo) %>%
filter(stock %in% longStks$stock)
}
byDat <- cleanPST(byDat, stockInfo)
write.csv(byDat, here("data", "salmonData", "CLEANcwtInd_age2SR_BY.csv"),
row.names = FALSE)
eyDat <- cleanPST(eyDat, stockInfo)
write.csv(eyDat, here("data", "salmonData", "CLEANcwtInd_age2SR_OEY.csv"),
row.names = FALSE)
#How many stocks per region?
byDat %>%
group_by(region) %>%
summarize(nStocks = length(unique(stock)))
byDat %>%
group_by(jurisdiction) %>%
summarize(nStocks = length(unique(stock)))
byDat <- read.csv(here("data/salmonData/CLEANcwtInd_age2SR_BY.csv"),
stringsAsFactors = FALSE)
byDat <- byDat %>%
select(region %in% c("LFR", "MFR", "UFR", "ECVI"))
head(byDat)
byDat <- byDat %>%
filter(region %in% c("LFR", "MFR", "UFR", "ECVI"))
byDat <- read.csv(here("data/salmonData/CLEANcwtInd_age2SR_BY.csv"),
stringsAsFactors = FALSE)
#focus on subset of BC pops for initial analyses
byDatTrim <- byDat %>%
filter(region %in% c("LFR", "MFR", "UFR", "ECVI"))
#Convert to matrices (necessary for DFA)
byMat <- byDatTrim %>%
select(BY, stock, surv) %>%
spread(key = stock, value = surv) %>%
select(-BY) %>%
as.matrix() %>%
t()
byMat
broodYrs <- unique(byDatTrim$BY)
colnames(byMat) <- broodYrs
byMat
nStks <- nrow(byMat)
nYrs <- ncol(byMat)
?zscore
zScore(byMatZ)
zscore(byMatZ)
zscore(byMat)
byMatZ <- MARSS::zscore(byMat)
mean(byMatZ[1,])
mean(byMatZ[1,], na.rm=T)
nStks
#focus on subset of BC pops for initial analyses
byDatTrim <- byDat %>%
filter(region %in% c("LFR", "MFR", "UFR"\))
byDat <- read.csv(here("data/salmonData/CLEANcwtInd_age2SR_BY.csv"),
stringsAsFactors = FALSE)
#focus on subset of BC pops for initial analyses
byDatTrim <- byDat %>%
filter(region %in% c("LFR", "MFR", "UFR"))
#Convert to matrices (necessary for DFA)
byMat <- byDatTrim %>%
select(BY, stock, surv) %>%
spread(key = stock, value = surv) %>%
select(-BY) %>%
as.matrix() %>%
t()
broodYrs <- unique(byDatTrim$BY)
colnames(byMat) <- broodYrs
nStks <- nrow(byMat)
nYrs <- ncol(byMat)
#standardize
byMatZ <- MARSS::zscore(byMat)
byMatZ
#preliminary model fit test
modelList <- list(m = 2, R = "diagonal and unequal")
?MARSS.dfa
#preliminary model fit test
modelList <- list(m = 2, R = "diagonal and unequal")
cntrList <- list(maxit = 1000)
cntrList <- list(maxit = 100)
dfaTest <- MARSS(byMatZ, model = model.list, z.score = TRUE, form = "dfa",
control = cntrList)
dfaTest <- MARSS(byMatZ, model = modelList, z.score = TRUE, form = "dfa",
control = cntrList)
cntrList <- list(maxit = 1000)
dfaTest <- MARSS(byMatZ, model = modelList, z.score = TRUE, form = "dfa",
control = cntrList)
