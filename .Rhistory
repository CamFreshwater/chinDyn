subDir
fitDFA
for (i in seq_along(inRSeq)) {
Ncores <- detectCores()
inRDum <- inRSeq[i]
cl <- makeCluster(Ncores - 2) #save two cores
registerDoParallel(cl)
clusterEvalQ(cl, c(library(MARSS), library(here), library(Rcpp),
library(RcppArmadillo)))
clusterExport(cl, c("byMatZ", "inRDum", "inMList", "fitDFA", "subDir"),
envir=environment())
tic("run in parallel")
parLapply(cl, inMList, function(x) {
fitDFA(byMatZ, inR = inRDum, inM = x, maxIteration = 1000,
subDirName = subDir)
})
stopCluster(cl) #end cluster
toc()
}
summ <- getTopDFA(subDir)
summ[[2]]
## Explore fit of top model
mod1 <- summ[[1]]
estZ <- coef(mod1, type = "matrix")$Z
#retrieve rotated matrix
invH <- if (ncol(estZ) > 1) {
varimax(estZ)$rotmat
} else if (ncol(estZ) == 1) {
1
}
summ[[1]]
coef(mod1, type= "matrix")
coef(mod1)
summary(mod1)
subDir
tt <- getTopDFA("salishSeaOnly_short_BY")
tt[[1]]
mod1 <- tt[[1]]
estZ <- coef(mod1, type = "matrix")$Z
#retrieve rotated matrix
invH <- if (ncol(estZ) > 1) {
varimax(estZ)$rotmat
} else if (ncol(estZ) == 1) {
1
}
coef(mod1, type = "matrix")$Z
subDirName <- subDir
subDirName
dirPath <- here::here("data", "dfaFits", subDirName)
modOutNames <- list.files(dirPath, pattern="\\.rds$")
modOut <- data.frame(model = rep(NA, times = length(modOutNames)),
AICc = NA
)
for(i in 1:length(modOutNames)){ #make list of lists!
dum <- readRDS(paste(dirPath, modOutNames[i], sep="/"))
modOut[i, "model"] <- modOutNames[i]
modOut[i, "AICc"] <- ifelse(is.null(dum$AICc), NA, dum$AICc)
}
aicTable <- modOut %>%
arrange(AICc)
aicTable
topModelName <- aicTable %>%
filter(AICc == min(AICc, na.rm = TRUE)) %>%
select(model) %>%
as.character()
topModel <- readRDS(paste(dirPath, topModelName, sep = "/"))
str(topModel)
nStks
par(mod1)
warnings()
mod1$par$Z
coef(mod1, type = "matrix")$Z
coef(mod1)
str(mod1)
mod1[["par"]][["Z"]]
mod1[["call"]][["m"]]
mod1[["call"]]
mod1[["call"]]$m
mod1$call$m
mod1$call$model$m
matrix(mod1[["par"]][["Z"]], ncol = mod1$call$model$m)
## Strong support for using diagonal and unequal covariance matrix and
# intermediate number of trends
ddd <- getTopDFA("salishSeaOnly_short_BY")
str(ddd)
subDir <- "salishSeaOnly_short_BY" #for data cropped at 1985
inRSeq <- c("diagonal and unequal", "equalvarcov")
dfaSummary <- getTopDFA(subDir)
dfaSummary[[2]] #prints AIC table
mod1 <- dfaSummary[[1]]
estZ <- coef(mod1, type = "matrix")$Z
#retrieve rotated matrix
invH <- if (ncol(estZ) > 1) {
varimax(estZ)$rotmat
} else if (ncol(estZ) == 1) {
1
}
estZ
dfaTest <- MARSS(byMatZ, model = modelList, z.score = TRUE, form = "dfa",
control = cntrList, method = "BFGS-kf")
listOfPackages <- c("here", "MARSS", "tidyverse", "ggplot2", "parallel",
"doParallel", "foreach", "tictoc")
lapply(listOfPackages, require, character.only = TRUE)
dfaTest <- MARSS(byMatZ, model = modelList, z.score = TRUE, form = "dfa",
control = cntrList, method = "BFGS-kf")
modelList <- list(m = 2, R = "diagonal and equal")
cntrList <- list(maxit = 200)
dfaTest <- MARSS(byMatZ, model = modelList, z.score = TRUE, form = "dfa",
control = cntrList, method = "BFGS-kf")
dfaTest <- MARSS(byMatZ, model = modelList, z.score = TRUE, form = "dfa",
control = cntrList, method = "kem")
coef(dfaTest)
coef(dfaTest, type = "matrix")
coef(dfaTest, type = "matrix")$Z
str(dfaTest)
coef(dfaTest)
coef(mod1)
summ <- getTopDFA(subDir)
summ[[2]]
## Explore fit of top model
mod1 <- summ[[1]]
coef(mod1)
coef(mod1, type = "matrix")$Z
?coef
listOfPackages <- c("here", "MARSS", "tidyverse", "ggplot2", "parallel",
"doParallel", "foreach", "tictoc")
lapply(listOfPackages, require, character.only = TRUE)
byDat <- read.csv(here("data/salmonData/CLEANcwtInd_age2SR_BY.csv"),
stringsAsFactors = FALSE)
eyDat <- read.csv(here("data/salmonData/CLEANcwtInd_age2SR_OEY.csv"),
stringsAsFactors = FALSE)
#focus on subset of BC pops for initial analyses
byDatTrim <- byDat %>%
filter(region %in% c("LFR", "MFR", "UFR", "ECVI", "SPGSD", "NPGSD"))%>%
group_by(stock) %>%
mutate(survZ = as.numeric(scale(surv))) %>%
ungroup(stock) %>%
arrange(region) %>%
mutate(stock = factor(stock, unique(stock))) %>%
select(-stockName, -jurisdiction, -lat, -long)
## Explore fit of top model
mod1 <- summ[[1]]
estZ <- MARSS::coef(mod1, type = "matrix")$Z
estZ <- coef(mod1, type = "matrix")$Z
#retrieve rotated matrix
invH <- if (ncol(estZ) > 1) {
varimax(estZ)$rotmat
} else if (ncol(estZ) == 1) {
1
}
## Factor loadings
#rotate factor loadings
rotZ <- (estZ %*% invH) %>%
as.data.frame() %>%
mutate(stock = stkID) %>%
inner_join(byDatTrim %>% select(stock, region), by = "stock") %>%
gather(key = "trend", value = "loading", -stock, -region) %>%
distinct() %>%
arrange(region) %>%
mutate(trend = fct_recode(as.factor(trend),
trend1 = "V1",
trend2 = "V2",
trend3 = "V3",
trend4 = "V4"),
stock = factor(stock, unique(stock)))
subDir
subDir <- "salishSeaOnly_BY"
summ <- getTopDFA(subDir)
summ[[2]]
## Explore fit of top model
mod1 <- summ[[1]]
estZ <- coef(mod1, type = "matrix")$Z
#retrieve rotated matrix
invH <- if (ncol(estZ) > 1) {
varimax(estZ)$rotmat
} else if (ncol(estZ) == 1) {
1
}
## Factor loadings
#rotate factor loadings
rotZ <- (estZ %*% invH) %>%
as.data.frame() %>%
mutate(stock = stkID) %>%
inner_join(byDatTrim %>% select(stock, region), by = "stock") %>%
gather(key = "trend", value = "loading", -stock, -region) %>%
distinct() %>%
arrange(region) %>%
mutate(trend = fct_recode(as.factor(trend),
trend1 = "V1",
trend2 = "V2",
trend3 = "V3",
trend4 = "V4"),
stock = factor(stock, unique(stock)))
ggplot(rotZ, aes(x = stock, y = loading, fill = region)) +
geom_col() +
theme_sleekX(axisSize = 9, legendSize = 0.7) +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
facet_wrap(~trend)
ggplot(rotZ, aes(x = stock, y = loading, fill = region)) +
geom_col() +
samSim::theme_sleekX(axisSize = 9, legendSize = 0.7) +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
facet_wrap(~trend)
## Trends
#rotate trends
rotTrends <- (solve(invH) %*% mod1$states) %>%
t() %>%
as.data.frame() %>%
mutate(year = broodYrs) %>%
gather(key = "trend", value = "est", -year) %>%
mutate(trend = fct_recode(as.factor(trend),
trend1 = "V1",
trend2 = "V2",
trend3 = "V3",
trend4 = "V4"))
ggplot(rotTrends, aes(x = year, y = est)) +
geom_line() +
theme_sleekX() +
geom_hline(yintercept = 0, colour = "red") +
facet_wrap(~trend)
ggplot(rotTrends, aes(x = year, y = est)) +
geom_line() +
samSim::theme_sleekX() +
geom_hline(yintercept = 0, colour = "red") +
facet_wrap(~trend)
## Plot fitted estimates
modOutCI <- broom::augment(mod1, interval = "confidence") %>%
dplyr::rename(stock = .rownames) %>%
inner_join(byDatTrim %>% select(stock, region), by = "stock") %>%
distinct() %>%
mutate(year = t + 1970,
stock = as.factor(stock)) %>%
arrange(region)
ggplot(modOutCI) +
geom_line(aes(x = year, y = .fitted)) +
geom_point(aes(x = year, y = y, colour = region)) +
geom_ribbon(aes(x = year, ymin = .conf.low, ymax = .conf.up), linetype = 2,
alpha = 0.2) +
facet_wrap(~stock)
listOfPackages <- c("here", "bayesDFA", "tidyverse", "ggplot2", "parallel",
"doParallel", "foreach", "tictoc")
lapply(listOfPackages, require, character.only = TRUE)
install.packages("bayesDFA")
devtools::install_github("fate-ewi/bayesdfa")
install.packages("bayesDFA")
install.packages("bayesDFA")
if(!require(installr)) { install.packages("installr"); require(installr)}
updateR(F, T, T, F, T, F, T)
listOfPackages <- c("here", "bayesDFA", "tidyverse", "ggplot2", "parallel",
"doParallel", "foreach", "tictoc")
lapply(listOfPackages, require, character.only = TRUE)
#helper functions to fit and post-process DFA
source(here("R/functions/dfaFunctions.R"))
byDat <- read.csv(here("data/salmonData/CLEANcwtInd_age2SR_BY.csv"),
stringsAsFactors = FALSE)
#focus on subset of BC pops for initial analyses
byDatTrim <- byDat %>%
filter(region %in% c("LFR", "MFR", "UFR", "ECVI", "SPGSD", "NPGSD")) %>%
group_by(stock) %>%
# mutate(survZ = as.numeric(scale(surv))) %>%
ungroup(stock) %>%
arrange(region) %>%
mutate(stock = factor(stock, unique(stock))) %>%
select(-stockName, -jurisdiction, -lat, -long)
byMatZ <- byDatTrim %>%
# select(BY, stock, survZ) %>%
# spread(key = stock, value = survZ) %>%
select(BY, stock, surv) %>%
spread(key = stock, value = surv) %>%
select(-BY) %>%
as.matrix() %>%
t()
broodYrs <- unique(byDatTrim$BY)
colnames(byMatZ) <- broodYrs
nStks <- nrow(byMatZ)
nYrs <- ncol(byMatZ)
stkID <- rownames(byMatZ)
?fit_dfa
require("bayesDFA")
install.packages("bayesDFA")
libPath
libPaths
.libPaths
.libPaths()
devtools::install_github("fate-ewi/bayesdfa")
require(bayesDFA)
install.packages("bayesDFA")
install.packages('bayesdfa')
?fit_dfa
require(bayesdfa)
install.packages('bayesdfa')
require(bayesdfa)
require(bayesdfa)
.libPaths("C:/Users/FRESHWATERC/Documents/R/R-3.6.0/library")
.libPaths
.libPaths()
require("bayesdfa")
install.packages("bayesdfa")
require("bayesdfa")
listOfPackages <- c("here", "bayesDFA", "tidyverse", "ggplot2", "parallel",
"doParallel", "foreach", "tictoc")
lapply(listOfPackages, require, character.only = TRUE)
listOfPackages <- c("here", "bayesdfa", "tidyverse", "ggplot2", "parallel",
"doParallel", "foreach", "tictoc")
lapply(listOfPackages, require, character.only = TRUE)
eyDat <- read.csv(here("data/salmonData/CLEANcwtInd_age2SR_OEY.csv"),
stringsAsFactors = FALSE)
#focus on subset of BC pops for initial analyses
eyDatTrim <- eyDat %>%
filter(region %in% c("LFR", "MFR", "UFR", "ECVI", "SPGSD", "NPGSD")) %>%
group_by(stock) %>%
# mutate(survZ = as.numeric(scale(surv))) %>%
ungroup(stock) %>%
arrange(region) %>%
mutate(stock = factor(stock, unique(stock))) %>%
select(-stockName, -jurisdiction, -lat, -long)
eyMatZ <- eyDatTrim %>%
# select(BY, stock, survZ) %>%
# spread(key = stock, value = survZ) %>%
select(OEY, stock, surv) %>%
spread(key = stock, value = surv) %>%
select(-OEY) %>%
as.matrix() %>%
t()
broodYrs <- unique(eyDatTrim$BY)
entryYrs <- unique(eyDatTrim$BY)
entryYrs <- unique(eyDatTrim$OEY)
colnames(eyMatZ) <- entryYrs
nStks <- nrow(eyMatZ)
nYrs <- ncol(eyMatZ)
stkID <- rownames(eyMatZ)
eyMatZ
f1 <- fit_dfa(y = eyMatZ, num_trends = 2, zscore = TRUE, iter = 1000, chains = 4,
thin = 1)
r1 <- totate_trends(f1)
r1 <- rotate_trends(f1)
plot_fitted(f1)
str(f1)
plot_fitted
plot_loadings(r1)
str(r1)
range(r1$trends_lower)
range(r1$trends_upper)
is_converged(f1, threshold = 1.05)
plot_fitted(f1)
plot_trends(r1)
find_dfa_trends
eyMat <- eyDatTrim %>%
# select(BY, stock, survZ) %>%
# spread(key = stock, value = survZ) %>%
select(OEY, stock, surv) %>%
spread(key = stock, value = surv) %>%
select(-OEY) %>%
as.matrix() %>%
t()
?find_dfa_trends
ttt <- eyMat[1:5, ]
ttt
ttt <- eyMat[1:8, ]
mins <- c(1, 4)
maxs <- c(3, 6)
mins <- list(1, 4)
maxs <- list(3, 6)
ranges <- list(mins, maxs)
ranges
ranges <- data.frame(min = c(1, 4),
max = c(3, 6))
ranges
split(ranges, seq(nrow(ranges)))
ranges <- data.frame(min = c(1, 4),
max = c(3, 6)) %>%
split(., seq(nrow(.)))
ranges
ranges <- data.frame(min = c(1, 4),
max = c(3, 6)) %>%
split(., seq(nrow(.)))
ranges <- list(mins, maxs)
# for (i in seq_along(inRSeq)) {
Ncores <- detectCores()
cl <- makeCluster(Ncores - 2) #save two cores
registerDoParallel(cl)
clusterEvalQ(cl, c(library(bayesdfa), library(here), library(Rcpp),
library(RcppArmadillo)))
clusterExport(cl, c("ttt", "find_dfa_trends", "ranges"),
envir=environment())
tic("run in parallel")
dum <- parLapply(cl, ranges, function(x) {
find_dfa_trends(y = ttt, iter = 250, kmin = x$min, kmax = x$max,
chains = 1, compare_normal = FALSE, zscore = TRUE,
variance = c("equal", "unequal"))
})
ranges$min
ranges[[1]]$min
ranges <- data.frame(min = c(1, 4),
max = c(3, 6)) %>%
split(., seq(nrow(.)))
ranges
ranges[[1]]
ranges[[1]]$min
Ncores <- detectCores()
cl <- makeCluster(Ncores - 2) #save two cores
registerDoParallel(cl)
clusterEvalQ(cl, c(library(bayesdfa), library(here), library(Rcpp),
library(RcppArmadillo)))
clusterExport(cl, c("ttt", "find_dfa_trends", "ranges"),
envir=environment())
tic("run in parallel")
dum <- parLapply(cl, ranges, function(x) {
find_dfa_trends(y = ttt, iter = 250, kmin = x$min, kmax = x$max,
chains = 1, compare_normal = FALSE, zscore = TRUE,
variance = c("equal", "unequal"))
})
find_dfa_trends(y = ttt, iter = 250, kmin = ranges[[1]]$min, kmax = ranges[[1]]$max,
chains = 1, compare_normal = FALSE, zscore = TRUE,
variance = "equal")
stopCluster(cl) #end cluster
toc()
Ncores <- detectCores()
cl <- makeCluster(Ncores - 2) #save two cores
registerDoParallel(cl)
clusterEvalQ(cl, c(library(bayesdfa), library(here), library(Rcpp),
library(RcppArmadillo)))
clusterExport(cl, c("ttt", "find_dfa_trends", "ranges"),
envir=environment())
tic("run in parallel")
dum <- parLapply(cl, ranges, function(x) {
find_dfa_trends(y = ttt, iter = 150, kmin = x$min, kmax = x$max,
chains = 1, compare_normal = FALSE, zscore = TRUE,
variance = "equal")
})
stopCluster(cl) #end cluster
toc()
str(dum)
dum[[1]]$summary
dum[[2]]$summary
tic("run in parallel")
find_dfa_trends(y = ttt, iter = 150, kmin = 1, kmax = 6,
chains = 1, compare_normal = FALSE, zscore = TRUE,
variance = c("equal", "unequal"))
tic("run in parallel")
find_dfa_trends(y = ttt, iter = 150, kmin = 1, kmax = 6,
chains = 1, compare_normal = FALSE, zscore = TRUE,
variance = "equal")
toc()
dum[[2]][[1]]
do.call(dum, rbind)
do.call(rbind, dum)
ranges <- data.frame(min = c(1, 3, 5, 7),
max = c(2, 4, 6, 8)) %>%
split(., seq(nrow(.)))
ranges
ranges <- data.frame(min = c(1, 3, 5, 7),
max = c(2, 4, 6, 8)) %>%
split(., seq(nrow(.)))
# for (i in seq_along(inRSeq)) {
Ncores <- detectCores()
cl <- makeCluster(Ncores - 2) #save two cores
registerDoParallel(cl)
clusterEvalQ(cl, c(library(bayesdfa), library(here), library(Rcpp),
library(RcppArmadillo)))
clusterExport(cl, c("eyMat", "find_dfa_trends", "ranges"),
envir=environment())
tic("run in parallel")
dum <- parLapply(cl, ranges, function(x) {
find_dfa_trends(y = eyMat, iter = 1200, kmin = x$min, kmax = x$max,
chains = 4, compare_normal = TRUE, zscore = TRUE,
variance =  c("equal", "unequal"))
})
dum
options(mc.cores = parallel::detectCores())
f1 <- fit_dfa(y = eyMat, num_trends = 2, zscore = TRUE, iter = 1000, chains = 4,
thin = 1, control = list(adapt_delta = 0.99, max_treedepth = 20))
f1 <- fit_dfa(y = eyMat, num_trends = 2, zscore = TRUE, iter = 1000, chains = 4,
thin = 1, control = list(adapt_delta = 0.95, max_treedepth = 20))
is_converged(f1, threshold = 1.05)
?is_converged
f1 <- fit_dfa(y = eyMat, num_trends = 2, zscore = TRUE, iter = 1500, chains = 4,
thin = 1, control = list(adapt_delta = 0.95, max_treedepth = 20))
is_converged(f1, threshold = 1.05)
launch_shinystan(f1$model)
shinystan::launch_shinystan(f1$model)
ShinyStan::launch_shinystan(f1$model)
install.packages("shinystan")
shinystan::launch_shinystan(f1$model)
options(mc.cores = parallel::detectCores())
f1 <- fit_dfa(y = eyMat, num_trends = 2, zscore = TRUE, iter = 2000, chains = 4,
thin = 1, control = list(adapt_delta = 0.9, max_treedepth = 20))
is_converged(f1, threshold = 1.05)
shinystan::launch_shinystan(f1$model)
shinystan::launch_shinystan(f1$model)
tic()
f1 <- fit_dfa(y = eyMat, num_trends = 2, zscore = TRUE, iter = 2500, chains = 4,
thin = 1, control = list(adapt_delta = 0.9, max_treedepth = 20))
toc()
is_converged(f1, threshold = 1.05)
shinystan::launch_shinystan(f1$model)
r1 <- rotate_trends(f1)
r1 <- rotate_trends(f1)
plot_trends(r1)
plot_fitted(f1)
plot_loadings(r1)
plot_loadings(r1) +
xlim(-3, 3)
plot_loadings(r1)
plot_loadings
plot_loadings(r1) +
ylim(-3, 3)
tic()
f1 <- fit_dfa(y = eyMat, num_trends = 5, zscore = TRUE, iter = 3000, chains = 4,
thin = 1, control = list(adapt_delta = 0.9, max_treedepth = 20))
toc()
is_converged(f1, threshold = 1.05)
