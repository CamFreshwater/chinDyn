---
title: "Bayesian Chinook DFA"
author: "Cam Freshwater"
date: "May 9, 2019"
output: html_document
---

After preliminary runs with chinook data noticed issues with estimating states for early portion of time series. Specifically the lack of data for certain time series mean that the estimated states were predicting (potentially) unreasonably high historical survival (these data are saved in `data/dfaFits/salishSeaOnly`). 

The `shortSalishSeaDFA.Rmd` provides one means of resolving this issue, by cropping the data. Here we use a Bayesian DFA, which is better able to estimate uncertainty in gappy time series, as an alternative means of exploring patterns in the data. Additonally the Bayesian DFA models can account for student-t process variance distributions and explicit tests for different regimes (e.g. 1970s vs. now).

First analysis will focus, as before, on Salish Sea only stocks so that these results can be compared to the ML models. Second analysis will include a broader range of stocks.

```{r loadAndClean}
listOfPackages <- c("here", "bayesdfa", "tidyverse", "ggplot2", "parallel", 
                    "doParallel", "foreach", "tictoc")
lapply(listOfPackages, library, character.only = TRUE)

#helper functions to fit and post-process DFA
source(here("R/functions/dfaFunctions.R"))

eyDat <- read.csv(here("data/salmonData/CLEANcwtInd_age2SR_OEY.csv"), 
                  stringsAsFactors = FALSE)

#focus on subset of BC pops for initial analyses
eyDatTrim <- eyDat %>% 
  filter(region %in% c("LFR", "MFR", "UFR", "ECVI", "SPGSD", "NPGSD")) %>% 
  group_by(stock) %>% 
  # mutate(survZ = as.numeric(scale(surv))) %>%
  ungroup(stock) %>% 
  arrange(region) %>% 
  mutate(stock = factor(stock, unique(stock))) %>% 
  select(-stockName, -jurisdiction, -lat, -long)

eyMat <- eyDatTrim %>%
  select(OEY, stock, surv) %>%
  spread(key = stock, value = surv) %>%
  select(-OEY) %>% 
  as.matrix() %>% 
  t()
entryYrs <- unique(eyDatTrim$OEY)
colnames(eyMat) <- entryYrs

nStks <- nrow(eyMat)
nYrs <- ncol(eyMat)
stkID <- rownames(eyMat)
```

Example below shows a 2 trend model (arbitrarily chosen) with loadings and trends. Notice that the uncertainty estimates are much larger at the beginning of the time series.

```{r bayesDFATestRun}
options(mc.cores = parallel::detectCores())

tic()
f1 <- fit_dfa(y = eyMat, num_trends = 5, zscore = TRUE, iter = 3000, chains = 4,
              thin = 1, control = list(adapt_delta = 0.9, max_treedepth = 20))
toc()
is_converged(f1, threshold = 1.05)
shinystan::launch_shinystan(f1$model)

r1 <- rotate_trends(f1)
plot_trends(r1)
plot_fitted(f1)
plot_loadings(r1) +
  ylim(-3, 3)
```

Initially ran model selection with up to 4 trends, both normal and student-t process variance, and independent or equal observation error. Some convergence issues, but strong support for independent error structures and at least 4 trends. Likely little utility in running with a larger number.

```{r modelComp}
# tic()
# fitModels <- find_dfa_trends(y = eyMat, iter = 3000, kmin = 1, kmax = 4, 
#                              chains = 4, compare_normal = TRUE, zscore = TRUE,
#                              variance =  c("equal", "unequal"),
#                              control = list(adapt_delta = 0.9, 
#                                             max_treedepth = 20))
# toc()
# saveRDS(fitModels, here::here("data", "dfaBayesFits",
#                               "salSeaOnly_findTrends.rds"))

fitModels$summary
f4 <- fitModels$best_model

```

In actuality 4 trends seems excessive. Two are quite similar and looic seems higher than estimates for three trend models.

```{r evalTopModel}
tic()
f4 <- fit_dfa(y = eyMat, num_trends = 4, zscore = TRUE, iter = 3000, chains = 4,
              thin = 1, estimate_nu = TRUE, 
              control = list(adapt_delta = 0.95, max_treedepth = 20))
toc()

shinystan::launch_shinystan(f4$model)
is_converged(f4, threshold = 1.05)

r4 <- rotate_trends(f4)
plot_trends(r4)
plot_fitted(f4)
plot_loadings(r4) +
  ylim(-3, 3)
```

Run preliminary global evaluation fitting up to 4 trends to larger full dataset (include both student-t and standard).

```{r fitModelAcrossRegions}
#focus on subset of BC pops for initial analyses
eyDatFull <- eyDat %>% 
  # filter(region %in% c("LFR", "MFR", "UFR", "ECVI", "SPGSD", "NPGSD", "WCVI",
  #                      "CBC", "JFUCA", "WACST", "HOODC")) %>%
  filter(!region %in% c("LCOLR", "MCOLR", "UCOLR", "SEAK", "TBR", "NBC", 
                        "ORCST")) %>%
  arrange(region) %>% 
  mutate(stock = factor(stock, unique(stock))) %>% 
  select(-stockName, -jurisdiction, -lat, -long)

eyMatFull <- eyDatFull %>%
  select(OEY, stock, surv) %>%
  spread(key = stock, value = surv) %>%
  select(-OEY) %>% 
  as.matrix() %>% 
  t()
entryYrs <- unique(eyDatTrim$OEY)
colnames(eyMatFull) <- entryYrs

nStks <- nrow(eyMatFull)
nYrs <- ncol(eyMatFull)
stkID <- rownames(eyMatFull)

tic()
fitModelsAll <- find_dfa_trends(y = eyMatFull, iter = 3500, kmin = 1, kmax = 4,
                             chains = 4, compare_normal = TRUE, zscore = TRUE,
                             variance =  "unequal",
                             control = list(adapt_delta = 0.95,
                                            max_treedepth = 20))
toc()
saveRDS(fitModelsAll, here::here("data", "dfaBayesFits",
                              "fullBasin_findTrends.rds"))

#set up trend inputs to allow for parallel processing
# ranges <- data.frame(min = c(5, 7),
#                      max = c(6, 8)) %>%
#   split(., seq(nrow(.)))
# 
# Ncores <- detectCores()
# cl <- makeCluster(Ncores) #save two cores
# registerDoParallel(cl)
# clusterEvalQ(cl, c(library(bayesdfa), library(here), library(Rcpp),
#                    library(RcppArmadillo)))
# clusterExport(cl, c("eyMat", "find_dfa_trends", "ranges"),
#               envir=environment())
# tic("run in parallel")
# dum <- parLapply(cl, ranges, function(x) {
#   find_dfa_trends(y = eyMat, iter = 3000, kmin = x$min, kmax = x$max,
#                   chains = 4, compare_normal = TRUE, zscore = TRUE,
#                   variance =  "unequal",  
#                   control = list(adapt_delta = 0.95, max_treedepth = 20))
# })
# stopCluster(cl) #end cluster
# toc()
```