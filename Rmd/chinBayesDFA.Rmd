---
title: "Bayesian Chinook DFA"
author: "Cam Freshwater"
date: "May 9, 2019"
output: html_document
---

After preliminary runs with chinook data noticed issues with estimating states for early portion of time series. Specifically the lack of data for certain time series mean that the estimated states were predicting (potentially) unreasonably high historical survival (these data are saved in `data/dfaFits/salishSeaOnly`). 

The `shortSalishSeaDFA.Rmd` provides one means of resolving this issue, by cropping the data. Here we use a Bayesian DFA, which is better able to estimate uncertainty in gappy time series, as an alternative means of exploring patterns in the data. Additonally the Bayesian DFA models can account for student-t process variance distributions and explicit tests for different regimes (e.g. 1970s vs. now).

First analysis will focus, as before, on Salish Sea only stocks so that these results can be compared to the ML models. Second analysis will include a broader range of stocks.

```{r loadAndClean}
listOfPackages <- c("here", "bayesdfa", "tidyverse", "ggplot2", "parallel", 
                    "doParallel", "foreach", "tictoc")
lapply(listOfPackages, library, character.only = TRUE)

#helper functions to fit and post-process DFA
source(here("R/functions/dfaFunctions.R"))

eyDat <- read.csv(here("data/salmonData/CLEANcwtInd_age2SR_OEY.csv"), 
                  stringsAsFactors = FALSE)

#focus on subset of BC pops for initial analyses
eyDatTrim <- eyDat %>% 
  filter(region %in% c("LFR", "MFR", "UFR", "ECVI", "SPGSD", "NPGSD")) %>% 
  group_by(stock) %>% 
  # mutate(survZ = as.numeric(scale(surv))) %>%
  ungroup(stock) %>% 
  arrange(region) %>% 
  mutate(stock = factor(stock, unique(stock))) %>% 
  select(-stockName, -jurisdiction, -lat, -long)

eyMat <- eyDatTrim %>%
  select(OEY, stock, surv) %>%
  spread(key = stock, value = surv) %>%
  select(-OEY) %>% 
  as.matrix() %>% 
  t()
entryYrs <- unique(eyDatTrim$OEY)
colnames(eyMat) <- entryYrs

nStks <- nrow(eyMat)
nYrs <- ncol(eyMat)
stkID <- rownames(eyMat)
```

Example below shows a 2 trend model (arbitrarily chosen) with loadings and trends. Notice that the uncertainty estimates are much larger at the beginning of the time series.

```{r bayesDFATestRun}
options(mc.cores = parallel::detectCores())

tic()
f1 <- fit_dfa(y = eyMat, num_trends = 5, zscore = TRUE, iter = 3000, chains = 4,
              thin = 1, control = list(adapt_delta = 0.9, max_treedepth = 20))
toc()
is_converged(f1, threshold = 1.05)
shinystan::launch_shinystan(f1$model)

r1 <- rotate_trends(f1)
plot_trends(r1)
plot_fitted(f1)
plot_loadings(r1) +
  ylim(-3, 3)
```

Strong support for independent covariance structures, three trends and student-t 
distribution. However fitting the independent covariance structures takes a very long time (~20 hrs for 3 models). Compare results (fit and loadings) to see if additional computational cost is justified.

```{r modelComp}
datIn <- data.frame(normal = c(FALSE, TRUE), 
                     var = c("unequal", "equal")) %>%
  split(., seq(nrow(.)))

# Ncores <- detectCores()
# cl <- makeCluster(Ncores) #save two cores
# registerDoParallel(cl)
# clusterEvalQ(cl, c(library(bayesdfa), library(here), library(Rcpp),
#                    library(RcppArmadillo)))
# clusterExport(cl, c("eyMat", "find_dfa_trends", "datIn"),
#               envir=environment())
# tic("run in parallel")
# dum <- parLapply(cl, datIn, function(x) {
#   find_dfa_trends(y = eyMat, iter = 3500, kmin = 1, kmax = 3,
#                   chains = 4, compare_normal = x$normal, zscore = TRUE,
#                   variance =  x$var,
#                   control = list(adapt_delta = 0.96, max_treedepth = 20))
# })
# stopCluster(cl) #end cluster
# toc()

# saveRDS(dum, here::here("data", "dfaBayesFits",
#                         "salishSea_diffCorStructures_findTrends.rds"))

dum <- readRDS(here::here("data", "dfaBayesFits",
                        "salishSea_diffCorStructures_findTrends.rds"))
rbind(dum[[1]]$summary, dum[[2]]$summary) %>% 
  arrange(looic)

```

The independent variance structure does provide much less uncertainty on the trend estimates and the loadings estimates are much more robust, presumably by accounting for differences among time series in how gappy they are. However the over fit on individual trends is fairly similar. 

```{r trendsAndLoadingsCov}
indMod <- dum[[1]]$best_model
equalMod <- dum[[2]]$best_model

shinystan::launch_shinystan(equalMod$model)
is_converged(indMod, threshold = 1.05)

indR <- rotate_trends(indMod)
indTrends <- plot_trends(indTrends)
equalR <- rotate_trends(equalMod)
equalTrends <- plot_trends(equalTrends)
ggpubr::ggarrange(indTrends, equalTrends, ncol = 1, nrow = 2)

indLoadings <- plot_loadings(indR) +
  ylim(-2, 2)
equalLoadings <- plot_loadings(equalR) +
  ylim(-2, 2)
ggpubr::ggarrange(indLoadings, equalLoadings, ncol = 1, nrow = 2)

png(here("figs", "dfa", "salishSea_3trend_indCor_fits.png"), height = 5, 
    width = 6, units = "in", res = 300)
plot_fitted(indMod)
dev.off()

png(here("figs", "dfa", "salishSea_3trend_eqCor_fits.png"), height = 5, 
    width = 6, units = "in", res = 300)
plot_fitted(equalMod)
dev.off()
```

For now it's probably best to just fit equal observation variance models and up to three trends per group, including both student-t and normal distributions.

```{r fitModelAcrossRegions}
#focus split eyDat to run each group separately
eyDatFull <- eyDat %>% 
  mutate(lat = as.numeric(lat),
         long = as.numeric(long),
         aggReg = case_when(
           (is.na(lat)) ~ "north",
           (lat > 52 & !region == "UFR") ~ "north",
           (region %in% c("JFUCA", "LCOLR", "MCOLR", "ORCST", "UCOLR", "WACST",
                          "WCVI")) ~ "south",
           TRUE ~ "SS"
         )) %>% 
  mutate(grp = paste(smoltType, aggReg, sep = "_")) %>% 
  arrange(grp) %>% 
  mutate(stock = factor(stock, unique(stock))) %>% 
  filter(!grp %in% c("oceantype_north", "streamtype_south")) %>% 
  select(-stockName, -jurisdiction, -lat, -long)

#split into lists 
convMat <- function(mat) {
  mat %>% 
    select(OEY, stock, surv) %>%
    spread(key = stock, value = surv) %>%
    select(-OEY) %>% 
    as.matrix() %>% 
    t()
}
survList <- split(eyDatFull, eyDatFull$grp) %>% 
 lapply(., convMat)

#set up trend inputs to allow for parallel processing
# Ncores <- detectCores()
# cl <- makeCluster(Ncores - 4) #save two cores
# registerDoParallel(cl)
# clusterEvalQ(cl, c(library(bayesdfa), library(here), library(Rcpp),
#                    library(RcppArmadillo), library(dplyr)))
# clusterExport(cl, c("find_dfa_trends", "survList"), envir=environment())
# tic("run in parallel")
# dum <- parLapply(cl, survList, function(x) {
#   maxTrends <- min(nrow(x) - 1, 3)
#   find_dfa_trends(y = x, iter = 4000, kmin = 1, kmax = maxTrends,
#                   chains = 4, compare_normal = TRUE, zscore = TRUE,
#                   variance =  "equal",
#                   control = list(adapt_delta = 0.97, 
#                                  max_treedepth = 20))
# })
# stopCluster(cl) #end cluster
# toc()

# saveRDS(dum, here::here("data", "dfaBayesFits",
#                         "coastWide_diffCorStructures_findTrends.rds"))
```

Oddly all groups favor relatively complex models with at least 3 trends. Student-t models typically do approximately as well, suggesting there is little support for fitting more complex heavy-tailed variance structures.

```{r groupModSel}
dum <- readRDS(here::here("data", "dfaBayesFits",
                        "coastWide_diffCorStructures_findTrends.rds"))
lapply(seq_along(survList), function(x) 
  dum[[x]]$summary %>% 
    arrange(looic) %>% 
    mutate(group = names(survList)[x])
  ) %>% 
  do.call(rbind, .)
```

```{r groupTrends}
trendsByGroups <- function(x) {
  mod <- x$best_model
  plot_trends(mod)
}
trendList <- lapply(seq_along(dum), function(x) {
  mod <- dum[[x]]$best_model
  rotTrends <- rotate_trends(mod)
  p <- plot_trends(rotTrends)
  return(p)
  })
for (i in seq_along(trendList)) {
  p <- trendList[[i]] +
    ggtitle(names(survList)[i])
  print(p)
}
ggpubr::ggarrange(trendList[[1]], trendList[[2]], trendList[[3]], trendList[[2]],
                  ncol = 1, nrow = 4)
```